{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "script_path = \"/home/aolivepe/EcoAVI-Parallel/fid.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([464, 1, 96, 128])\n"
     ]
    }
   ],
   "source": [
    "# Set directory path\n",
    "dir_path = os.path.abspath(os.path.join(script_path, '..','..', '..', '..', 'data', 'aolivepe', 'preprocessedData', 'vr480x640AVI_croped_128x96'))\n",
    "\n",
    "\n",
    "# Get list of video files in directory\n",
    "video_files = [os.path.join(dir_path, f) for f in os.listdir(dir_path) if f.endswith('.avi')]\n",
    "\n",
    "# Initialize empty list to store frames\n",
    "frames = []\n",
    "\n",
    "# Loop through each video file\n",
    "for video_file in video_files:\n",
    "    # Open video file with OpenCV\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "    # Loop through each frame in video\n",
    "    while True:\n",
    "        # Read frame from video\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # If end of video, break loop\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert frame to grayscale\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Add frame to list of frames\n",
    "        frames.append(frame_gray)\n",
    "\n",
    "    # Release OpenCV video capture object\n",
    "    cap.release()\n",
    "\n",
    "# Convert list of frames to tensor\n",
    "real_images = torch.tensor(frames)\n",
    "\n",
    "# Add channel dimension to frames tensor\n",
    "real_images = real_images.unsqueeze(1)\n",
    "\n",
    "print(real_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([464, 1, 96, 128])\n"
     ]
    }
   ],
   "source": [
    "# Set directory path\n",
    "dir_path = os.path.abspath(os.path.join(script_path, '..','..', '..', '..', 'data', 'aolivepe', 'preprocessedData', 'vr480x640AVI_croped_128x96'))\n",
    "\n",
    "\n",
    "# Get list of video files in directory\n",
    "video_files = [os.path.join(dir_path, f) for f in os.listdir(dir_path) if f.endswith('.avi')]\n",
    "\n",
    "# Initialize empty list to store frames\n",
    "frames = []\n",
    "\n",
    "# Loop through each video file\n",
    "for video_file in video_files:\n",
    "    # Open video file with OpenCV\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "    # Loop through each frame in video\n",
    "    while True:\n",
    "        # Read frame from video\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # If end of video, break loop\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert frame to grayscale\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Add frame to list of frames\n",
    "        frames.append(frame_gray)\n",
    "\n",
    "    # Release OpenCV video capture object\n",
    "    cap.release()\n",
    "\n",
    "# Convert list of frames to tensor\n",
    "fake_images = torch.tensor(frames)\n",
    "\n",
    "# Add channel dimension to frames tensor\n",
    "fake_images = fake_images.unsqueeze(1)\n",
    "\n",
    "print(fake_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-fidelity in /home/aolivepe/miniconda3/envs/video-diffusion/lib/python3.10/site-packages (0.3.0)\n",
      "Requirement already satisfied: scipy in /home/aolivepe/miniconda3/envs/video-diffusion/lib/python3.10/site-packages (from torch-fidelity) (1.10.1)\n",
      "Requirement already satisfied: torch in /home/aolivepe/miniconda3/envs/video-diffusion/lib/python3.10/site-packages (from torch-fidelity) (2.0.0)\n",
      "Requirement already satisfied: Pillow in /home/aolivepe/miniconda3/envs/video-diffusion/lib/python3.10/site-packages (from torch-fidelity) (9.4.0)\n",
      "Requirement already satisfied: numpy in /home/aolivepe/miniconda3/envs/video-diffusion/lib/python3.10/site-packages (from torch-fidelity) (1.23.5)\n",
      "Requirement already satisfied: torchvision in /home/aolivepe/miniconda3/envs/video-diffusion/lib/python3.10/site-packages (from torch-fidelity) (0.15.0)\n",
      "Requirement already satisfied: tqdm in /home/aolivepe/miniconda3/envs/video-diffusion/lib/python3.10/site-packages (from torch-fidelity) (4.65.0)\n",
      "Requirement already satisfied: filelock in /home/aolivepe/miniconda3/envs/video-diffusion/lib/python3.10/site-packages (from torch->torch-fidelity) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /home/aolivepe/miniconda3/envs/video-diffusion/lib/python3.10/site-packages (from torch->torch-fidelity) (4.4.0)\n",
      "Requirement already satisfied: sympy in /home/aolivepe/miniconda3/envs/video-diffusion/lib/python3.10/site-packages (from torch->torch-fidelity) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/aolivepe/miniconda3/envs/video-diffusion/lib/python3.10/site-packages (from torch->torch-fidelity) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /home/aolivepe/miniconda3/envs/video-diffusion/lib/python3.10/site-packages (from torch->torch-fidelity) (3.1.2)\n",
      "Requirement already satisfied: requests in /home/aolivepe/miniconda3/envs/video-diffusion/lib/python3.10/site-packages (from torchvision->torch-fidelity) (2.28.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/aolivepe/miniconda3/envs/video-diffusion/lib/python3.10/site-packages (from jinja2->torch->torch-fidelity) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aolivepe/miniconda3/envs/video-diffusion/lib/python3.10/site-packages (from requests->torchvision->torch-fidelity) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/aolivepe/miniconda3/envs/video-diffusion/lib/python3.10/site-packages (from requests->torchvision->torch-fidelity) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/aolivepe/miniconda3/envs/video-diffusion/lib/python3.10/site-packages (from requests->torchvision->torch-fidelity) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/aolivepe/miniconda3/envs/video-diffusion/lib/python3.10/site-packages (from requests->torchvision->torch-fidelity) (1.26.14)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/aolivepe/miniconda3/envs/video-diffusion/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy->torch->torch-fidelity) (1.2.1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span>get_ipython().system(<span style=\"color: #808000; text-decoration-color: #808000\">' pip install torch-fidelity'</span>)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3 fid = FrechetInceptionDistance(normalize=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>fid.update(real_images, real=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5 </span>fid.update(fake_images, real=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>)                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/aolivepe/miniconda3/envs/video-diffusion/lib/python3.10/site-packages/torchmetrics/image/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">f</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">id.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">225</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">222 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(feature, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">int</span>):                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">223 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>num_features = feature                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">224 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> _TORCH_FIDELITY_AVAILABLE:                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>225 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ModuleNotFoundError</span>(                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">226 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"FrechetInceptionDistance metric requires that `Torch-fidelity` is i</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">227 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\" Either install as `pip install torchmetrics[image]` or `pip instal</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">228 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>)                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ModuleNotFoundError: </span>FrechetInceptionDistance metric requires that `Torch-fidelity` is installed. Either install as\n",
       "`pip install torchmetrics<span style=\"font-weight: bold\">[</span>image<span style=\"font-weight: bold\">]</span>` or `pip install torch-fidelity`.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m3\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0mget_ipython().system(\u001b[33m'\u001b[0m\u001b[33m pip install torch-fidelity\u001b[0m\u001b[33m'\u001b[0m)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3 fid = FrechetInceptionDistance(normalize=\u001b[94mTrue\u001b[0m)                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0mfid.update(real_images, real=\u001b[94mTrue\u001b[0m)                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0mfid.update(fake_images, real=\u001b[94mFalse\u001b[0m)                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m6 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/aolivepe/miniconda3/envs/video-diffusion/lib/python3.10/site-packages/torchmetrics/image/\u001b[0m\u001b[1;33mf\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mid.py\u001b[0m:\u001b[94m225\u001b[0m in \u001b[92m__init__\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m222 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(feature, \u001b[96mint\u001b[0m):                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m223 \u001b[0m\u001b[2m│   │   │   \u001b[0mnum_features = feature                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m224 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m _TORCH_FIDELITY_AVAILABLE:                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m225 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mModuleNotFoundError\u001b[0m(                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m226 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mFrechetInceptionDistance metric requires that `Torch-fidelity` is i\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m227 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m Either install as `pip install torchmetrics[image]` or `pip instal\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m228 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mModuleNotFoundError: \u001b[0mFrechetInceptionDistance metric requires that `Torch-fidelity` is installed. Either install as\n",
       "`pip install torchmetrics\u001b[1m[\u001b[0mimage\u001b[1m]\u001b[0m` or `pip install torch-fidelity`.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "! pip install torch-fidelity\n",
    "\n",
    "fid = FrechetInceptionDistance(normalize=True)\n",
    "fid.update(real_images, real=True)\n",
    "fid.update(fake_images, real=False)\n",
    "\n",
    "print(f\"FID: {float(fid.compute())}\")\n",
    "# FID: 177.7147216796875"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "video-diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
